{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes - 20news\n",
    "In this exercise we use the naive Bayes method for text classification. \n",
    "In the [accompanying notebook](./HW1_2IIG0_24_25.ipynb), the `20newsgroups` dataset is loaded for four classes of newsgroups: `rec.autos`, `rec.motorcycles`, `rec.sport.baseball`, `rec.sport.hockey`. \n",
    "The text documents are transformed to a bag of words representation, given by a data matrix $D∈{0,1}^{n×d}$ where each row represents a document and every column a word. $D$ is an indicator matrix of the words that occur in each document."
   ],
   "id": "28f87093faf6c6bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T14:57:20.624023Z",
     "start_time": "2024-11-21T14:57:19.802190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import sklearn"
   ],
   "id": "13eca0d51b68c633",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T14:57:47.358044Z",
     "start_time": "2024-11-21T14:57:46.623667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ],
   "id": "dc1f5f0435c0ff33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5a\n",
    "Compute the class prior probabilities $p(y)$:\n",
    "* $p(y = 0)$\n",
    "* $p(y = 1)$\n",
    "* $p(y = 2)$\n",
    "* $p(y = 3)$"
   ],
   "id": "79ceb074a8af632d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5b\n",
    "What are the log-probabilities of the word 'naive' given each class? Use Laplace smoothing with $\\alpha=1e−5$. Note that the log is in ML as a default the natural logarithm to the base of $e$.\n",
    "Assuming that $x_{naive}$ denotes the random variable for the feature-word 'naive', compute the following probabilities:\n",
    "* $\\log p(x_{naive}=1∣y=0)$\n",
    "* $\\log p(x_{naive}=1∣y=1)$\n",
    "* $\\log p(x_{naive}=1∣y=2)$"
   ],
   "id": "a096cbff3a7b0f64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9d646fa637d56b2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5c\n",
    "What is the posterior probability that a document belongs to the classes `rec.autos`, `rec.motorcycles`, `rec.sport.baseball`, or `rec.sport.hockey`, given that the words 'autos', 'motorcycles', 'baseball', or 'hockey' respectively appear in the document? \n",
    "Use Bayes' theorem to compute the posterior probability for each of the following:\n",
    "* $p(y=0∣x_{auto}=1)$\n",
    "* $p(y=1∣x_{motorcycles}=1)$\n",
    "* $p(y=2∣x_{baseball}=1)$\n",
    "* $p(y=3∣x_{hockey}=1)$"
   ],
   "id": "27b39bd35b2895f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
