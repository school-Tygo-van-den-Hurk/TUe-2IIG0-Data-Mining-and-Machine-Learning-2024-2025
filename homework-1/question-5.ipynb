{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes - 20news\n",
    "In this exercise we use the naive Bayes method for text classification. \n",
    "In the [accompanying notebook](./HW1_2IIG0_24_25.ipynb), the `20newsgroups` dataset is loaded for four classes of newsgroups: `rec.autos`, `rec.motorcycles`, `rec.sport.baseball`, `rec.sport.hockey`. \n",
    "The text documents are transformed to a bag of words representation, given by a data matrix $D∈{0,1}^{n×d}$ where each row represents a document and every column a word. $D$ is an indicator matrix of the words that occur in each document."
   ],
   "id": "28f87093faf6c6bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:24:59.095340Z",
     "start_time": "2024-11-26T11:24:58.960973Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "13eca0d51b68c633",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:00.462311Z",
     "start_time": "2024-11-26T11:24:59.098863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ],
   "id": "dc1f5f0435c0ff33",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:00.782684Z",
     "start_time": "2024-11-26T11:25:00.774118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = train.target\n",
    "y_train"
   ],
   "id": "91ebb52a8698533c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, ..., 3, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:00.838945Z",
     "start_time": "2024-11-26T11:25:00.832426Z"
    }
   },
   "cell_type": "code",
   "source": "train.target_names",
   "id": "dd3c3c912bdf7f58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:01.434456Z",
     "start_time": "2024-11-26T11:25:00.888239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=5,token_pattern=\"[^\\\\W\\\\d_]+\", binary=True)\n",
    "D = vectorizer.fit_transform(train.data)\n",
    "D_test = vectorizer.transform(test.data)"
   ],
   "id": "dba59e829d270fc6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:01.486319Z",
     "start_time": "2024-11-26T11:25:01.478153Z"
    }
   },
   "cell_type": "code",
   "source": "vectorizer.get_feature_names_out()",
   "id": "2d5b65e1d88eb710",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaa', 'aamir', ..., 'zubov', 'zx', 'zz'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:01.541177Z",
     "start_time": "2024-11-26T11:25:01.530856Z"
    }
   },
   "cell_type": "code",
   "source": "np.where(vectorizer.get_feature_names_out() == 'naive')[0]",
   "id": "9f39017d6425559f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4299], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5a\n",
    "Compute the class prior probabilities $p(y)$:\n",
    "* $p(y = 0)$\n",
    "* $p(y = 1)$\n",
    "* $p(y = 2)$\n",
    "* $p(y = 3)$"
   ],
   "id": "79ceb074a8af632d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:01.592543Z",
     "start_time": "2024-11-26T11:25:01.585862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the class prior probabilities\n",
    "n = y_train.shape[0]\n",
    "p_y = np.zeros(4)\n",
    "for i in range(4):\n",
    "    p_y[i] = np.sum(y_train == i) / n\n",
    "p_y"
   ],
   "id": "7bb66510d2072850",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2486396 , 0.25031394, 0.24989535, 0.25115111])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5b\n",
    "What are the log-probabilities of the word 'naive' given each class? Use Laplace smoothing with $\\alpha=1e−5$. Note that the log is in ML as a default the natural logarithm to the base of $e$.\n",
    "Assuming that $x_{naive}$ denotes the random variable for the feature-word 'naive', compute the following probabilities:\n",
    "* $\\log p(x_{naive}=1∣y=0)$\n",
    "* $\\log p(x_{naive}=1∣y=1)$\n",
    "* $\\log p(x_{naive}=1∣y=2)$"
   ],
   "id": "a096cbff3a7b0f64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:02.196884Z",
     "start_time": "2024-11-26T11:25:01.636893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the log-probabilities of the word 'naive' given each class\n",
    "alpha = 1e-5\n",
    "D = vectorizer.fit_transform(train.data)\n",
    "D = D.toarray()\n",
    "n, d = D.shape\n",
    "log_p_x_y = np.zeros((4, d))\n",
    "for i in range(4):\n",
    "    log_p_x_y[i] = np.log((np.sum(D[y_train == i, :], axis=0) + alpha) / (np.sum(D[y_train == i, :]) + alpha * d))\n",
    "# print column 4299 (corresponding to the index of word naive)\n",
    "log_p_x_y[:, 4299]"
   ],
   "id": "b38cdc20d685c221",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.78571652, -10.07003614, -10.7793644 ,  -9.82897749])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 5c\n",
    "What is the posterior probability that a document belongs to the classes `rec.autos`, `rec.motorcycles`, `rec.sport.baseball`, or `rec.sport.hockey`, given that the words 'autos', 'motorcycles', 'baseball', or 'hockey' respectively appear in the document? \n",
    "Use Bayes' theorem to compute the posterior probability for each of the following:\n",
    "* $p(y=0∣x_{auto}=1)$\n",
    "* $p(y=1∣x_{motorcycles}=1)$\n",
    "* $p(y=2∣x_{baseball}=1)$\n",
    "* $p(y=3∣x_{hockey}=1)$"
   ],
   "id": "27b39bd35b2895f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:02.258451Z",
     "start_time": "2024-11-26T11:25:02.242371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find the indices of the words 'autos', 'motorcycles', 'baseball', and 'hockey'\n",
    "words = ['autos', 'motorcycles', 'baseball', 'hockey']\n",
    "indices = np.zeros(4, dtype=int)\n",
    "for i in range(4):\n",
    "    indices[i] = np.where(vectorizer.get_feature_names_out() == words[i])[0][0]\n",
    "indices"
   ],
   "id": "ce57cc5bd1e12259",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 402, 4219,  484, 2956])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:02.308722Z",
     "start_time": "2024-11-26T11:25:02.302694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the posterior probabilities \n",
    "# p(y=0|x_auto=1) = p(x_auto=1|y=0) * p(y=0) / p(x_auto=1)\n",
    "# p(x_auto=1) = sum(p(x_auto=1|y) * p(y))\n",
    "p_x_auto_1 = np.sum(np.exp(log_p_x_y[:, 402]) * p_y)\n",
    "p_y_0_x_auto_1 = np.exp(log_p_x_y[0, 402]) * p_y[0] / p_x_auto_1\n",
    "p_y_0_x_auto_1"
   ],
   "id": "e10126d6b1cb0ae9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999993053247772"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:02.358698Z",
     "start_time": "2024-11-26T11:25:02.353193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# p(y=1|x_motorcycles=1) = p(x_motorcycles=1|y=1) * p(y=1) / p(x_motorcycles=1)\n",
    "p_x_motorcycles_1 = np.sum(np.exp(log_p_x_y[:, 4219]) * p_y)\n",
    "p_y_1_x_motorcycles_1 = np.exp(log_p_x_y[1, 4219]) * p_y[1] / p_x_motorcycles_1\n",
    "p_y_1_x_motorcycles_1"
   ],
   "id": "161dc348c4fdbc97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026014911751483"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:02.409462Z",
     "start_time": "2024-11-26T11:25:02.404133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# p(y=2|x_baseball=1) = p(x_baseball=1|y=2) * p(y=2) / p(x_baseball=1)\n",
    "p_x_baseball_1 = np.sum(np.exp(log_p_x_y[:, 484]) * p_y)\n",
    "p_y_2_x_baseball_1 = np.exp(log_p_x_y[2, 484]) * p_y[2] / p_x_baseball_1\n",
    "p_y_2_x_baseball_1"
   ],
   "id": "bc5b8f1768a85701",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8596891709633955"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:25:02.461151Z",
     "start_time": "2024-11-26T11:25:02.455948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# p(y=3|x_hockey=1) = p(x_hockey=1|y=3) * p(y=3) / p(x_hockey=1)\n",
    "p_x_hockey_1 = np.sum(np.exp(log_p_x_y[:, 2956]) * p_y)\n",
    "p_y_3_x_hockey_1 = np.exp(log_p_x_y[3, 2956]) * p_y[3] / p_x_hockey_1\n",
    "p_y_3_x_hockey_1"
   ],
   "id": "9afeae44e10f1424",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811299872500109"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
